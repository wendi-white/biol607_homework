---
title: "Functions and Tidy Data"
author: "Wendi White"
date: "10/5/2020"
output: html_document
---

github: https://github.com/wendi-white/biol607_homework 

```{r}
#libraries
library(visdat)
library(skimr)
library(lubridate)
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
library(matrixStats)
```


1. Write a function that takes a vector and returns one bootstrapped sample from said vector. Demonstrate that it works.

```{r}
boot_samp <- function(my_vec) { #creat a function that takes vector (my_vec) and takesn one boostrapped sample one time with replacement
  out <- sample(my_vec,
                    size=length(my_vec), 
                    replace = TRUE)
  return(out) #return the new smaple
  }

boot_samp(c(1,4,5,2,4,5,6,1,3)) #test
```



2. Write a function that given a vector of values a request for some number of bootstraps (let’s call the parameter R), and a sample statistic function (e.g., mean, IQR, etc.) returns R number of values of that statistic. Have it default to R = 1000 and the function is mean. Show this works for 10 bootstrapped replicate draws of a mean from some vector. Do the values look reasonable? Compare to the actual mean of the vector. Make sure you are using the function(s) you wrote in #1

The values look reasonable as the mean of our vector is 3.444444. If you look at the 10 values given some fall above and some fall above this. Taking the mean of the bootstrap samples also gives you 3.8 which is pretty close to 3.444444. Doing the full 1000 replicates would make it even closer to 3.444444!

```{r}
boot_samp <- function(my_vec, R=1000) { #write a function that given a vector will request for R # (1000) of bootstraps 
  out <- replicate(R, sample(my_vec, #will return R # of statistic functions (mean)
                    size=length(my_vec), 
                    replace = TRUE) %>% mean)
  return(out)
}
boot_samp(c(1,4,5,2,4,5,6,1,3), R=10) #give vector and set sample size at 10 not 1000

mean(c(1,4,5,2,4,5,6,1,3)) #actual mean of vector is 3.444444

mean(c(3.444444, 3.333333, 3.666667, 5.222222, 3.888889, 3.222222, 4.000000, 3.555556, 3.666667, 4)) #just testing the mean of the bootstrapped samples




#got help from Jarrett and talked about functions. Think I understand them better so
#redid problem to check this work after
boot_samp_new <- function(boot_samp, R=1000, stat_funky=mean){
  out <- replicate(R, boot_samp %>% stat_funky)
  return(out)
}

boot_samp_new(c(1,5,10,1,2,13,100), R=10)
```

3. Write a function that, given a vector of values a request for some number of bootstraps, and a sample statistic function, returns the original value of the statistic as applied to the vector, the mean of the statistic generated by the bootstrapped reps, the upper and lower 95% CI of the bootstrapped statistic (e.g., the 0.025 and 0.975 quantile), and the bias (i.e., the original value of the statistic - the mean of the bootstrapped statistic). make sure you are using the function(s) you wrote in #1 and/or #2

Mean of vec= 3.444444
mean of bootstrapped vec= 3.424111
2.5% quantile= 2.333333 
97.5% quantile= 4.444444
bias= -0.01411111

```{r}
boot_samp <- function(my_vec, R=1000) { #write a function that given a vector will request for R # (1000) of bootstraps 
  out <- replicate(R, sample(my_vec, #will return R # of statistic functions (mean)
                    size=length(my_vec), 
                    replace = TRUE) %>% mean)
  return(out)
}
boot_samp(c(1,4,5,2,4,5,6,1,3)) #1000 means from a given vector

#returns the original value of the mean as applied to the vector
mean_of_vec <- function(my_vec) {
  out_2 <- mean(my_vec)
  return(out_2)
}
mean_of_vec(c(1,4,5,2,4,5,6,1,3)) 

#returns the mean of the statistic generated by the bootstrapped reps, 
mean_of_boot <- function(my_vec, R=1000) { #write a function that given a vector will request for R # (1000) of bootstraps 
  out <- replicate(R, sample(my_vec, #will return R # of statistic functions (mean)
                    size=length(my_vec), 
                    replace = TRUE) %>% mean)
  m <- mean(out)
  return(m)
}
mean_of_boot(c(1,4,5,2,4,5,6,1,3))

#returns the upper and lower 95% CI of the bootstrapped statistic (e.g., the 0.025 and 0.975 quantile), 
quantiles_of_boot <- function(my_vec, R=1000) {  
  out <- replicate(R, sample(my_vec,
                    size=length(my_vec), 
                    replace = TRUE) %>% mean)
  quants <- quantile(out, probs = 0.025) #calls to return lower quant of bootstrapped stat
  return(quants)
}
quantiles_of_boot(c(1,4,5,2,4,5,6,1,3))

quantiles_of_boot_up <- function(my_vec, R=1000) {
  out <- replicate(R, sample(my_vec, 
                    size=length(my_vec), 
                    replace = TRUE) %>% mean)
  quants_up <- quantile(out, probs = 0.975) ##return upper quant of bootstrapped stat
  return(quants_up)
}
quantiles_of_boot_up(c(1,4,5,2,4,5,6,1,3))

#equation for mean of vec- mean of bootstrapped vec
bias_samp <- mean_of_vec(c(1,4,5,2,4,5,6,1,3)) - mean_of_boot(c(1,4,5,2,4,5,6,1,3))



boot_samp_three <- function(boot_samp, R=1000, stat_funky=mean){
  out <- replicate(R, boot_samp %>% stat_funky)
  return(out)
}

boot_samp_new(c(1,5,10,1,2,13,100), R=10)


```


4. FiveThirtyEight keeps a great archive of poll data at https://projects.fivethirtyeight.com/polls/. The presidential general election polling data is freely available at https://projects.fivethirtyeight.com/polls-page/president_polls.csv with question, poll id, and cycle defining a unique poll.

    4a. Download and look at the data. Is it long or wide?
    
    Data is long b/c each row is its own data point.

```{r}
election_data <- read.csv("https://projects.fivethirtyeight.com/polls-page/president_polls.csv")
names(election_data)
str(election_data)
summary(election_data)
vis_dat(election_data)
skim(election_data)
```


    4b. Get just the polling data for this last week (from 9/29 to today). Filter on start_date. Also filter down to just Biden and Trump (see candidate_name or answer). Extra credit for using {lubridate} for this, but you can just do a messy %in% string match.

```{r}
election_data_parsed <- election_data %>% #taking election data and pulling out all the dates I want and which candidates I want to make a new DF
  filter(start_date %in% c("9/29/20", 
                           "9/30/20", 
                           "10/1/20", 
                           "10/2/20", 
                           "10/3/20", 
                           "10/4/20", 
                           "10/5/20"
                           )) %>%
  filter(candidate_name %in% c("Joseph R. Biden Jr." , 
                               "Donald Trump"))
```


    4c. OK, this is your sample. What’s the bootstrapped average percentage for each candidate for nationwide polls (state == "")? Note, this answer will not match 538 given their weighting by poll trustworthiness.

Biden= 46.09821%
Trump= 46.13142%

```{r}
#BIDEN
bs_avg_biden <- election_data_parsed %>% #filtering out all of state so it's nationwide and then the Biden only data so I can look at his boostrapped avg percent (used function from #2 to boostrap)
  filter(state=="") %>% 
  filter(answer=="Biden") %>%
  summarize(avg_pct_Biden= mean(boot_samp(election_data_parsed$pct))) 
#46.09821

#TRUMP
bs_avg_trump <- election_data_parsed %>%#filtering out all of state so it's nationwide and then the Trump only data so I can look at his boostrapped avg percent (used function from #2 to boostrap)
  filter(state=="") %>%
  filter(answer=="Trump") %>%
  summarize(avg_pct_Trump= mean(boot_samp(election_data_parsed$pct))) 
 #46.13142
```


    4d. What is the average difference between the two candidates by state and national polls? Note, you’ll need to make this a wide data frame to answer! And, well, try the pivot without this advice first, but then… make a unique ID by pasting together the question_id, poll_id, and state. Then select the ID, state, answer, and pct. Also filter out NA diffs

```{r}
wide_election_data <- election_data_parsed %>% #making the data wide data frame by fisrt creating a unique id with question/poll id and state. Then selecting for the new id, state, answer and % columns.
  mutate(id_new = (paste(question_id, poll_id, state, sep = "_"))) %>%
   select("id_new", "state", "answer", "pct")

bt_wide <- wide_election_data %>% #now make it wide
  pivot_wider(names_from = answer, #takes values from answer columns and makes them their own col with the pct values
              values_from= pct)

state_dif <- bt_wide %>% #creates a table that's got a new column that lets us look at the differences between trump and biden % (trump-Biden).
  mutate(state_BT_diff = Trump - Biden)%>%
  filter(!is.na(state_BT_diff)) #filter all the na rows out
```


5. replicate() has been our friend, but we’ve always had to be a little hacky with it. We’ve either had to fold in means, or use tricksy functions like colMeans and the like. BUT - what’s interesting about replicate() is that, if you ask it to turn back raw draws from a random number generator - or anything with more than one value - it gives you a matrix or array.

    5a. So, I want you to, using the mean and SD of Biden’s national polling average (you’ll need to calculate it!) from above, simulate 1000 draws from that population with a sample size of 50. What are the dimensions of the object. What are in the rows and columns?

I get 1000 columns and 50 rows! So each row is 1000 samples of each simulation. 

```{r}
biden_nat <- election_data_parsed %>% #takes the data and filters out just for Biden
  filter(answer== "Biden")

samp <- rnorm(n=50, 
              mean= mean(biden_nat$pct), #takes 50 samples of data and creates a normal vector given our known mean and sd that I pulled from the biden data
              sd= sd(biden_nat$pct)) 

samp_2 <- replicate(1000, sample(samp, 
                    size=length(samp), #boostrapps the new sample 1000 times
                    replace = TRUE))

str(samp_2)
```


    5b. Yuck. Can you turn this into something usable? Say, first make it a tibble or data frame, and then pivot it to long, such that you end up with a column that has an identifier for sim and a column with a single value from that sim? (Oh, and for all columns, cols = everything())

```{r}
clean_crazy_obj <- as.data.frame(samp_2) #create df

piv_clean_crazy_obj <- clean_crazy_obj%>% #make it long by using all the oclumns and then putting the % values to each sim (1-50)
  pivot_longer(cols = everything(),
               names_to= "sim",
               values_to="percentage")
```


    5c. For each sim, what’s the bootsrapped mean and CI? Plot it! And tell us how often it’s greater than the initial mean. E.C. for the plot showing the stats in order from low to high.
  
575 time it's greater than the inital mean

```{r}
plot_clean_crazy_obj <- piv_clean_crazy_obj %>% #create new df that we'll use to plot by grouping by each sim and then finding the mean, upper/lower quantiles 
  group_by(sim) %>%
  summarize("mean"= mean(percentage),
            "quantile_upper"= quantile(percentage, probs=0.975),
            "quantile_low"= quantile(percentage,probs =0.025)) 


final_plot_hopefully <- ggplot(plot_clean_crazy_obj,  #creating plot to show where boot means (all black data points) are relative to original means of the Biden data (red line)
       mapping = aes(x=sim,
                     y=mean,
                     ymin=quantile_low,
                     ymax=quantile_upper)) +
  geom_pointrange()+
  geom_hline(yintercept = 49.3023, linetype= "dotted", colour="red")

final_plot_hopefully

mean(biden_nat$pct) #to find mean for the y int. above 


length(plot_clean_crazy_obj$mean[plot_clean_crazy_obj$mean > mean(biden_nat$pct)])
```


    5d. So…. what is that plot showing? What are the concepts involved?

It's showing us that the bootstrapped means of our 50 simulations are falling around this mean that we found from the original data.